import sys, argparse, tom, multiprocessing, os, pickle, random
import tom_slim as ts
import site_frequency_spectrum as sfs_tools
from collections import Counter
from tom import brace

def orgPolyDict(organ_mutations,N):
	sfsDict = {}
	for i in organ_mutations.keys():
		orgDict = {}
		orgDictRaw = {}
		for q in organ_mutations[i]:
			if q[1] not in orgDictRaw.keys():
				orgDictRaw[q[1]] = [int(q[7])]
			else:
				orgDictRaw[q[1]].append(int(q[7]))
		for o in orgDictRaw.keys():
			orgDict[o] =sfs_tools.SFS_from_all_frequencies(orgDictRaw[o],N) 
#			print orgDict[o]
		sfsDict[i] = orgDict
	return sfsDict

def orgFixDict(fixed_organs):
	fixD = {}
	for i in fixed_organs.keys():
		orgFixD = Counter()
		for o in fixed_organs[i]:
			orgFixD[o[1]]+=1
		fixD[i] = orgFixD
	return fixD
			
def combinePolyFix(poly,fix):
	for i in fix.keys():
		for  j in fix[i]:
			try:
				if j not in poly[i].keys():
					poly[i][j] = [0]*len(poly[i][poly[i].keys()[0]])
					poly[i][j][-1] += fix[i][j]
				else:
					poly[i][j][-1] += fix[i][j]
			except KeyError:continue		
	return poly

def combineElements(polyfix,lengths):
	elDict = {}
	for i in polyfix.keys():
		sfs = []
		try:
			for j in polyfix[i].keys():
				if i == 'g1' and j == 'm1': ## for the case of exons
					elDict['syn'] = polyfix[i][j]
					continue
				if len(sfs) == 0:
					sfs = polyfix[i][j]
				else:
					sfs = sfs_tools.merge_SFS(sfs,polyfix[i][j])
		except KeyError:continue
		elDict[i] = sfs

	for i in elDict.keys():
		zero = lengths[i] - sum(elDict[i])
		elDict[i][0] = zero
	return elDict


def parseLengths(lengthDictRaw):
	lengthDict = {}
	for i in lengthDictRaw.keys():
		if i == 'g1':
			raw = lengthDictRaw[i]
			syn = raw * 0.25
			nonsyn = raw-syn
			lengthDict['syn'] = syn
			lengthDict['g1'] = nonsyn
		else:
			lengthDict[i] = lengthDictRaw[i]
	return lengthDict

def get_sfs_dict(slim_input,num=-1):
	x = ts.slim(slim_input,fixed = True,give_genomes=True)
	print x.genomes
	if not x.sanity:
		return [None,None]
	thresh = x.N*10
	
	polyDict = orgPolyDict(x.organ_mutations(),x.sampleN)
	lengthDict = parseLengths(x.organ_lengths())
#	print lengthDict
#	print polyDict
	fixedDict = x.organ_fixed(threshold = int(x.N)*10)
	
	fixD = orgFixDict(fixedDict)
	
	polyfix = combinePolyFix(polyDict,fixD)
	
	elDict = combineElements(polyfix,lengthDict)	
	print 'processed ' + x.name
	return [x.name,elDict]

def get_sfs_dict_from_sample(slim_input):
	x = ts.slim(slim_input,fixed = True,give_genomes=True)
	if not x.sanity:
		return [None,None]

	genomes = x.genome_dict()
	mutations = x.mutations_dict()
	lengthDict = parseLengths(x.organ_lengths())
	individuals = [random.choice(genomes.keys()) for i in range(20)]
	muts_by_organ = x.organ_mutations()
	new_muts = Counter()
	for g in individuals:
		for m in genomes[g]:
			new_muts[m] +=1
	polyDict = {} 
	for h in muts_by_organ.keys():
		mTypeDict = {}
		for m in muts_by_organ[h]:
			if new_muts[m[0]] == 0: continue
			if m[1] not in mTypeDict.keys():
				mTypeDict[m[1]] = [new_muts[m[0]]]
			else:
				mTypeDict[m[1]].append(new_muts[m[0]])
#		print h, mTypeDict
		mPoly = {}
		for k in mTypeDict.keys():
			mPoly[k] = sfs_tools.SFS_from_all_frequencies(mTypeDict[k],20) 
		polyDict[h] = mPoly

	thresh = x.N*10
	fixedDict = x.organ_fixed(threshold = int(x.N)*10)	
	fixD = orgFixDict(fixedDict)
	polyfix = combinePolyFix(polyDict,fixD)
	elDict = combineElements(polyfix,lengthDict)	

	
	print 'processed ' + x.name
	return [x.name,elDict]

def main():
	parser = argparse.ArgumentParser(description="Get the SFS for each mutation type in the simulation")
	parser.add_argument("-i","--input", 
		required = True,
		dest = "input", 
		type =str, 
		help = "Give the name of the gzipped, SLiM output")

	parser.add_argument("-o","--output", 
		required = True,
		dest = "output", 
		type =str, 
		help = "the name of the output")
	parser.add_argument("-t","--procs", 
		required = True,
		dest = "procs", 
		type =int, 
		help = "The number of processors to use")
	parser.add_argument("-n","--num", 
		required = False,
		dest = "num", 
		type =int, 
		help = "The number of individuals to downsample to",
		default = -1)

	args = parser.parse_args()
	finalDict = {}
	count = 0
	if args.num > 0:
		sfsDictFunc = get_sfs_dict_from_sample
	elif args.num == -1:
		sfsDictFunc = get_sfs_dict
	

	if args.procs == 1:	
		print 'Reading all SLiM output'
		for i in ts.slim_reader_gzip(args.input):
			count +=1
			print count
#				if count <25:
#					continue
	
			runDict = sfsDictFunc(i)
			
			finalDict[runDict[0]]=runDict[1]

#			if count == 10: continue
			#print runDict[0],runDict[1]
	elif args.procs > 1:
		p = multiprocessing.Pool(args.procs)
		print 'Reading all SLiM output'
		results = p.map( sfsDictFunc, ts.slim_reader_gzip(args.input))
		for j in results:
			if j[0] == None:continue 
			finalDict[j[0]]=j[1]
		
	
	pickle_jar = open(args.output,"wb")
	pickle.dump( finalDict , pickle_jar )
        pickle_jar.close()
	os.system("gzip "+args.output)

if '__name__':
	main()
